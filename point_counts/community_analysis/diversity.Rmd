---
title: "Site C Point Count Data: Songbird Diversity Analyses"
output:
  html_notebook:
    toc: TRUE
    toc_float: TRUE
---

Exploration of bird community metrics using Site C bird point count survey data.

What do I want to do?\
-Species richness and diversity\
-Expected diversity using rarefaction\
-Community structure exploration using ordination and cluster analysis\
-Indicator species analysis

-Multi-Species Occupancy Model (MSOM)

-is it possible that occupancy models may be better than abundance?

-Species co-occurrence - why?

-what about species association? pos, neg, neutral

# Setup

```{r message=FALSE}
# Packages
library(tidyverse)
library(here)
library(vegan)
library(BiodiversityR)
library(vcd)
library(indicspecies)         # Indicator species analysis
library(lme4)
library(glmmTMB)
library(MuMIn)
library(emmeans)
library(effects)
library(DHARMa)
library(doParallel)

```

Import the tidied raw songbird station and observation data, if no already in memory.

```{r global_options, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
options(scipen = 999)
```

# Approach

Need to determine how repeated samples will be dealt with.

For patterns of species richness, want to use sample (survey) and use site (station) as random effect. That is clear.

But what about other community analysis about composition, like sp accumulation and ordination? Could roll up surveys to station. The problem with this approach is that there are differnt number of surveys per station and any roll-up would introduce an effort bias. I think samples (surveys) must be used for all analyses.

Questions:

# Import and prep

Load the 5-min count data. Note for later: May need to create a surveyID (single variable identifier).

```{r Import, message=FALSE}
dat <- read_csv(here("point_counts", "data_processed", "song_wide_5min_100m.csv"))

# Survey covariats
survey_cov <- read_csv(here("point_counts", "data_processed", 
                            "survey_cov.csv")) %>% 
  mutate(Year = as_factor(Year))
  
```

Create the sp matrices for use in vegan.

```{r}
sp <- dat %>% 
  select(`B-ALFL`:`B-YRWA`)
```

Prepare env data and create lumped BHC variables.

```{r}
env <- dat %>% 
  select(`StationID`:`Survey Duration`) %>%
  mutate(Year = as_factor(Year)) %>% 
  mutate(BHC17 = case_when(
    BHC20 == "FBT" ~ "FBS/FBT",
    BHC20 == "FBS" ~ "FBS/FBT",
    BHC20 == "DSG" ~ "DSG/DSS",
    BHC20 == "DSS" ~ "DSG/DSS",
    TRUE ~ BHC20
    )) %>% 
  mutate(BHC17 = factor(BHC17, levels = c("CSH","CYF","CMF","DSH","DYF","DMF",
                                          "RSH","RYF","RMF", "FBS/FBT","WGR",
                                          "WSH","WRI","DSG/DSS","CUL","NVE", 
                                          "ANT")
                        )
         ) %>% 
  mutate(BHC8 = case_when(
    BHC20 == "CSH"	~ "Conif",
    BHC20 == "CYF"	~ "Conif",
    BHC20 == "CMF"	~ "Conif",
    BHC20 == "DSH"	~ "Decid",
    BHC20 == "DYF"	~ "Decid",
    BHC20 == "DMF"	~ "Decid",
    BHC20 == "RSH"	~ "RipForest",
    BHC20 == "RYF"	~ "RipForest",
    BHC20 == "RMF"	~ "RipForest",
    BHC20 == "FBS"	~ "Wetland",
    BHC20 == "FBT"	~ "Conif",
    BHC20 == "WGR"	~ "Wetland",
    BHC20 == "WSH"	~ "Wetland",
    BHC20 == "WRI"	~ "Wetland",
    BHC20 == "DSG"	~ "Dry slopes",
    BHC20 == "DSS"	~ "Dry slopes",
    BHC20 == "CUL"	~ "Cultiv",
    BHC20 == "NVE"	~ "Non-veg",
    BHC20 == "ANT"	~ "Anthropogenic")
    ) %>% 
  mutate(BHC8 = factor(BHC8, levels = c("Conif", "Decid", 'RipForest', 
                                            "Wetland", "Dry slopes", "Cultiv", 
                                            "Non-veg", "Anthropogenic")
                       )) %>% 
  mutate(ForestOpen = case_when(
           BHC8 == "Conif" ~ "Forest",
           BHC8 == "Decid" ~ "Forest",
           BHC8 == "RipForest" ~ "Forest",
           BHC8 == "Wetland" ~ "Open",
           BHC8 == "Dry Slopes" ~ "Open",
           BHC8 == "Cultiv" ~ "Open",
           BHC8 == "Non-veg" ~ "Open",
           BHC8 == "Anthropogenic" ~ "Open")) %>%
  left_join(survey_cov, by = c("StationID", "Visit", "Year", "Date", "Time"))
```

# Patterns of species richness

```{r paged.print=TRUE}
rich <- diversityresult(sp, index = "richness", method = "each site", sortit = FALSE, digits = 6)
shan <- diversityresult(sp, index = "Shannon", method = "each site", sortit = FALSE, digits = 6)
simp <- diversityresult(sp, index = "Simpson", method = "each site", sortit = FALSE, digits = 6)
divdat <- bind_cols(env, rich, shan, simp)

hist(divdat$richness)
hist(divdat$Shannon)
hist(divdat$Simpson)

# or
ggplot(divdat, aes(x=richness)) + 
  geom_histogram(binwidth = 1)

```

The richness data seems to fit poisson a bit better.

```{r paged.print=TRUE}

fit_poisson <- goodfit(divdat$richness, type = "poisson")
rootogram(fit_poisson)
summary(fit_poisson)

fit_nbinom <- goodfit(divdat$richness, type = "nbinomial")
rootogram(fit_nbinom)
summary(fit_nbinom)

```

Not sure how to make sense of the goodness of fit tests on Shannon div.

```{r paged.print=TRUE}

fit_poisson <- goodfit(divdat$Shannon, type = "poisson")
rootogram(fit_poisson)
summary(fit_poisson)

fit_nbinom <- goodfit(divdat$Shannon, type = "nbinomial")
rootogram(fit_nbinom)
summary(fit_nbinom)

```

Should be working with the valley upstream of dam only.
```{r}
divdat <- divdat %>% 
  filter(ValleyUpstDam == "Yes")

```


```{r}
divdat %>% 
  ggplot(aes(Year, richness)) +
  geom_boxplot()

```

## Model

```{r paged.print=TRUE}
model_full <- glmmTMB(richness ~ Year + ForestOpen + EastWest + TSSR + JDAY + 
                        (1|StationID),
                   data = divdat,
                   family = (poisson("log"))
                   )

# Not sur eif this is needed
# na.action = "na.fail")

dredge(model_full)

```

For the model with lowest AICc.

```{r}

model_sel <- glmmTMB(richness ~ Year + BHC8 + EastWest + JDAY +
                        (1|StationID),
                   data = divdat,
                   family = (poisson("log"))
                   )

summary(model_sel)

ae <- allEffects(model_sel)
plot(ae, residuals="TRUE")

```

## A test with Year as continuous

```{r paged.print=TRUE}
model_sel <- glmmTMB(richness ~ MonYear + ForestOpen + EastWest + JDAY + 
                        (1|StationID),
                   data = divdat,
                   family = (poisson("log"))
                   )

summary(model_sel)

ae <- allEffects(model_sel)
plot(ae, residuals="TRUE")
```

# Generalized Additive Model
```{r}
library(mgcv)
library(gamm)

divdat$MonYear <- divdat$MonYear + 2006
divdat$Easting <- divdat$Easting / 1000
divdat$Northing <- divdat$Northing / 1000

gam1 <- gam(richness ~ s(MonYear, k = 9) + s(Easting, Northing, k = 100) + s(JDAY)
            + s(TSSR) + s(BHC8, bs = 're'),
                   data = divdat,
                   family = (poisson("log")),
             method = 'REML'
                   )

gam.check(gam1)
appraise(gam1, method = "simulate")

plot.gam(gam1)

vis.gam(gam1)

```

## Follow-up

-   Could GAM help with interpretation?

-   Are there any other random effects that should be incorporated?

-   Does reducing the number of habitat classes help?

-   Are there any other variables that need to be accounted for?

-   The 2006-2012 data is so much higher. Are there any data methodological reasons?

    -   Review methods used.

    -   More random locations? Many are on habitat edges. Perhaps a bias toward surveys in richer habitats?

    -   Will be interesting to compare total species richness

# Species accumulation / rarefaction

iNext is the package for this. There is some ore though,

Basic, using vegan.

```{r}
sac <- specaccum(sp)
plot(sac, ci.type="polygon", ci.col="yellow")



```

# Ordination

## NMDS

Does not like empty rows, so need to filter out sites with no species. First have to join the sp and env data, then filter, then split.

```{r}
song_wide_5min_nonzero <- bind_cols(env, sp) %>% 
  filter(rowSums(select(., `B-ALFL`:`B-YRWA`)) > 1)
  
sp_nmds <- song_wide_5min_nonzero %>% 
  select(`B-ALFL`:`B-YRWA`)

env_nmds <- song_wide_5min_nonzero %>% 
  select(`StationID`:`SurveyDuration`, BHC8) %>% 
  mutate(SampleID = str_c(StationID, Visit, sep = "-"))
```

Run NMDS. Test using parallel processing.

First run without parallel, it took 33 minutes.

With parallel, 25 mins!

```{r}

# Set parallel processing
# registerDoParallel()

start.time <- proc.time() 

nmds <- metaMDS(sp_nmds, distance = "bray")

stop.time <- proc.time() 
run.time <- stop.time-start.time 
print(run.time) 
```

Plot the scores.

```{r}

data.scores <- as.data.frame(scores(nmds))

# add columns to data frame 
data.scores$SampleID <- env_nmds$SampleID
data.scores$BHC8 <- env_nmds$BHC8

n_plot <- ggplot(data.scores, aes(x = NMDS1, y = NMDS2)) + 
  geom_point(size = 2, aes(colour = BHC8))+ 
  theme(axis.text.y = element_text(colour = "black", size = 10, face = "bold"), 
        axis.text.x = element_text(colour = "black", face = "bold", size = 10), 
        legend.text = element_text(size = 10, face ="bold", colour ="black"), 
        legend.position = "right", axis.title.y = element_text(face = "bold", 
                                                               size = 11), 
        axis.title.x = element_text(face = "bold", size = 10, colour = "black"), 
        legend.title = element_text(size = 11, colour = "black", face = "bold"), 
        panel.background = element_blank(), 
        panel.border = element_rect(colour = "black", fill = NA, size = 1.2),
        legend.key=element_blank()) + 
  labs(x = "NMDS1", colour = "Species", y = "NMDS2") 
n_plot

```

There seem to be outliers that skew the ordination. I tried removing one, but another was just produced. Another approach may be needed.

# Indicator Species Analysis

Create the sp matrix. Same as the one for nmds with the null sites removed.

The groups matrix is BHC8.

```{r}
sp_indic <- sp_nmds
groups <- pluck(env_nmds$`BHC8`)
```

```{r}
indval <- multipatt(sp_indic, groups, control = how(nperm=999))
summary(indval)
```

Some of the results don't make sense.

Now try it 2016-2020 data.

```{r}
song_wide_5min_nonzero_2016plus <- bind_cols(env, sp) %>% 
  mutate(Year = as.numeric(Year)) %>% 
  filter(Year > 4) %>% 
  filter(rowSums(select(., `B-ALFL`:`B-YRWA`)) > 1)

sp_indic <- song_wide_5min_nonzero_2016plus %>% 
  select(`B-ALFL`:`B-YRWA`)

birds_select <- sp_indic %>% 
  map_dfr(., sum) %>% 
  t() %>% 
  as.data.frame() %>% 
  rownames_to_column("species") %>% 
  filter(V1 > 0)

sp_indic <- sp_indic %>% 
  select(any_of(birds_select$species))

env_indic <- song_wide_5min_nonzero_2016plus %>% 
  select(`StationID`:`SurveyDuration`, BHC8) %>% 
  mutate(SampleID = str_c(StationID, Visit, sep = "-"))

groups <- pluck(env_indic$`BHC8`)

 %>% 
```

```{r}
dist <- dist(sp_indic, method="euclidean")

hc <- hclust(dist, method = "complete")

summary(hc)

plot(hc)
```
