---
title: "Site C Point Count Data: Import, QA and Prep"
output:
  html_notebook:
    toc: TRUE
    toc_float: TRUE
---

This script is for import, tidy and quality assurance checks of the survey data.

To keep referential integrity, it seems best to join the three tables (stations, surveys and obs).

That way the visits can be properly renumbered (although that really only matter for the visit analysis)

# Setup

```{r message=FALSE}
# Packages
library(tidyverse)
library(readxl)
library(lubridate)
library(skimr)
library(here)
library(kableExtra)

```

```{r global_options, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
options(scipen = 999)
```

# Read and tidy data

The data imported below is a copy of the master data file that is located in the project Sharepoint site. Make sure it is up to date.

Set some nicer names for variables regularly used. Get rid of variables that will not be used in any analysis, just for cleaner tables.

```{r message=FALSE, warning=FALSE}
stations <- read_excel(here("point_counts", "data_raw", "Songto2020data.xlsx"), "Stations") %>% 
  rename(StationID = 'Sample Station Label',
         Easting = `Easting Sample Station`,
         Northing = `Northing Sample Station`) %>%
  mutate(Year = str_sub(`Survey Name`,-4)) %>% 
  select(StationID, Year, everything(), 
         -c(`Sample Station Photos`, `Sample Station Comments`,
            `UTM Zone Sample Station`, `Survey Name`, Station))

surveys <- read_excel(here("point_counts", "data_raw", "Songto2020data.xlsx"), 
                      "Surveys") %>% 
  rename(StationID = 'Sample Station Label') %>% 
  select(StationID, Visit, Date, Time, SurveyDuration) %>% 
  mutate(Date = as_date(Date), 
         Time = as_datetime(Time)) 
# Update the date in `Time` with correct date from `Date` 
date(surveys$Time) <- date(surveys$Date)
# Most analysis of the songbird data must account for temporal survey-level effects
# These variables can be created now and to be used later.
# Year, TSSR, YDAY, DSLS

obs <- read_excel(here("point_counts", "data_raw", "Songto2020data.xlsx"), 
                  "Observations",
                  col_types = c("text", "numeric", "text", "numeric", "text", "numeric",
                                "numeric", "numeric", "numeric", "numeric", 
                                "text", "text", "text", "text", "numeric", 
                                "numeric", "text", "guess", "guess", "guess", 
                                "guess", "guess"),
                  na = "NA") %>% 
  rename(StationID = 'Sample Station Label', SpCode = Species) %>% 
  select(StationID, Visit, SpCode, `Count 5 min`, `Count 0-3 min`, `Count 3-5 min`,          `Count 5-10 min`, Count, `Distance Category`, Flyovers) %>% 
  filter(str_detect(SpCode, "B-U", negate = TRUE)) # Clear out the unknowns

# Bring in the BC Bird list from BC Species and Ecosystem Explorer
BCbirds <- read_excel(here("point_counts", "data_raw", "Songto2019data.xlsx"), 
                      "BC_Bird_List") %>% 
  select(ID, `English Name`, `Scientific Name`, `Species Code`, Order, 
         `BC List`, COSEWIC, SARA) %>% 
  rename(SpCode = "Species Code") %>% 
  mutate(IsSongbird = ifelse(Order %in% c("Columbiformes", "Caprimulgiformes", 
                                          "Piciformes", "Passeriformes"), 
                             TRUE, 
                             FALSE))

```

# Check for errors

Check for duplicates in stations\$StationID.

```{r}
stations %>% 
  count(StationID) %>% 
  filter(n>1)
```

Check for duplicates in surveys\$StationID & Visit.

Note: There are some duplicates in 2011 data. Need to fix (2020-06-29).

```{r}
surveys %>% 
  count(StationID, Visit) %>% 
  filter(n>1)
```

Check to see if there is a match for StationID between stations and surveys. This can be done using a full join and then filter.

```{r}
# Join the two tables
StationID_match <- stations %>% 
  full_join(surveys, by = "StationID")
# Filter to check for StationID in `surveys` but not in `stations`.
StationID_match %>% filter(is.na(Year))
# Filter to check for StationID in `stations` but not in `surveys`.
StationID_match %>% filter(is.na(Visit))
```

Now check for match for StationID between 'surveys' and 'obs'. Note that stations and surveys must be clean before this is useful.

For the second "test", surveys that had no observations will also be listed.

```{r}
StationID_match <- surveys %>% 
  full_join(obs, by = c("StationID", "Visit"))
# Filter to check for `StationID $ Visit` in `obs` but not in `surveys`.
StationID_match %>% filter(is.na(Date))
# Filter to check for `StationID $ Visit` in `surveys` but not in `obs`.
# NB: This might be because of no birds observations rather than data entry error.
StationID_match %>% filter(is.na(SpCode))
```

Validate species codes in obs table.

NONE is used to indicate a survey with no observations.

```{r}
obs %>% 
  left_join(BCbirds, by = "SpCode") %>% 
  filter(is.na(`English Name`))
```

Check missing values (nulls).

```{r}
is.null(stations)
is.null(surveys)
is.null(obs)
```

# Create summary tables to see if any values out of range

Map station coordinates for anything out of range.

```{r}
stations %>% 
  ggplot(aes(x = Easting, y = Northing, colour = Year)) + 
  geom_point()
```

Summary by number of visits.

```{r message=FALSE}
visit_sum <- surveys %>% 
  group_by(StationID, Year = year(Date)) %>% 
  summarize(Visits = n()) %>% 
  mutate(Visits = as_factor(Visits)) %>% 
  group_by(Year, Visits) %>% 
  summarize("Number of Locations" = n())

# Make a summary table
visit_sum %>% 
  pivot_wider(id_cols = "Visits", 
              names_from = "Year", 
              values_from = "Number of Locations") %>% 
  replace(is.na(.), 0) %>% 
  kable()

# Plot for presentation
visit_sum %>% 
  ggplot(aes(x = as.character(Year), y = `Number of Locations`,
             fill = Visits)) +
  geom_bar(stat = "identity") +
#  scale_fill_brewer(palette="reds") +
  xlab("Year")
```

```{r paged.print=TRUE}
# Survey dates and times.
table(year(surveys$Date))
table(month(surveys$Date))
table(hour(surveys$Time))

# Observations counts
table(obs$Count)
# Distances
table(obs$`Distance Category`)
```

# Create wide format

-   Need to create two versions:

    -   Total count (regardless of survey duration), for use with QPAD or other analyses that can account for differing durations among surveys.

    -   Count in 5 minutes. This standardizes to 5 mins for analyses when accounting for durations is difficult.

-   Since some survey years were fixed radius and some unlimited, must select only the obs =\< 100 when using data for all years. If using the 2016 onward data, can use unlimited (data not produced in this script).

-   Filter for songbirds only.

-   Then reformat data to wide format for use in vegan: samples by species.

-   To make the wide matrix, it is necessary to join up with the survey data. This is because there were some surveys with no species detections and therefore do not appear in the observations table.

Make list of songbirds to filter data on:

```{r message=FALSE}
song_list <- BCbirds %>%
filter(IsSongbird == TRUE)
song_list <-song_list$SpCode

```

Create the filtered list of obs. Files written to 'data\_processed' so that subsequent analyses can load the data without running the scripts here.

For all duration data:

```{r message=FALSE}
song_wide <- obs %>% 
  left_join(surveys, by = c("StationID", "Visit")) %>% 
  filter(`Distance Category` != ">100") %>%
  filter(SpCode %in% song_list) %>% 
  filter(is.na(Flyovers)) %>% 
  group_by(StationID, Visit, SpCode) %>% 
  summarise(count = sum(Count)) %>% 
  pivot_wider(names_from = "SpCode", values_from = count, values_fill = 0) %>% 
  select(sort(names(.))) %>% 
  select(StationID, Visit, everything()) %>% 
  full_join(surveys, by = c("StationID", "Visit")) %>% 
  left_join(stations, by = "StationID") %>%
  select(StationID, Visit, Year, Footprint, `Mitigation Property`, Valley,
         ValleyUpstPine, ValleyUpstDam, BBFM_ID, 
         Easting, Northing, Longitude, Latitude, BHC20, Date, Time,
         SurveyDuration, `B-ALFL`:`B-YRWA`) %>% 
  replace(is.na(.), 0) %>% 
  arrange(StationID)

write_csv(song_wide, here("point_counts", "data_processed", "song_wide.csv"))
```

For the 5-min counts:

```{r message=FALSE}
song_wide_5min <- obs %>% 
  left_join(surveys, by = c("StationID", "Visit")) %>% 
  rowwise() %>% 
  mutate(count5 = 
           case_when(year(Date) > 2016 ~ sum(c(`Count 0-3 min`, `Count 3-5 min`),
                                             na.rm = TRUE),
                     TRUE ~ `Count 5 min`)) %>% 
  filter(`Distance Category` != ">100") %>%
  filter(SpCode %in% song_list) %>% 
  filter(is.na(Flyovers)) %>% 
  group_by(StationID, Visit, SpCode) %>% 
  summarise(count = sum(count5)) %>% 
  pivot_wider(names_from = "SpCode", values_from = count, values_fill = 0) %>% 
  select(sort(names(.))) %>% 
  select(StationID, Visit, everything()) %>% 
  full_join(surveys, by = c("StationID", "Visit")) %>% 
  left_join(stations, by = "StationID") %>%
  select(StationID, Visit, Year, Footprint, `Mitigation Property`, Valley,
         ValleyUpstPine, ValleyUpstDam, BBFM_ID, 
         Easting, Northing, Longitude, Latitude, BHC20, Date, Time, 
         SurveyDuration, `B-ALFL`:`B-YRWA`) %>% 
  replace(is.na(.), 0) %>% 
  arrange(StationID)

write_csv(song_wide, here("point_counts", "data_processed", "song_wide_5min.csv"))
    
```

Clean up temp files.

```{r}
rm(StationID_match)
rm(visit_sum)
```

# 
